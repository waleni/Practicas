{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a446246",
   "metadata": {},
   "source": [
    "### Stacking para Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b139c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare ensemble to each baseline classifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7751b37",
   "metadata": {},
   "source": [
    "Usamos la función make_classification() para crear un problema de clasificación binaria sintética con 1,000 ejemplos y 20 características de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "    return X, y\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e93fda",
   "metadata": {},
   "source": [
    "La función get_stacking() a continuación define el modelo StackingClassifier definiendo primero una lista de tuplas para los cinco modelos base, luego definiendo el metamodelo de regresión logística para combinar las predicciones de los modelos base usando una validación cruzada de 5 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d879238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression()))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('cart', DecisionTreeClassifier()))\n",
    "    level0.append(('svm', SVC()))\n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca487e9",
   "metadata": {},
   "source": [
    "Incluimos el conjunto de apilamiento en la lista de modelos para evaluar, junto con los modelos independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccceaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LogisticRegression()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    models['bayes'] = GaussianNB()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff51d76",
   "metadata": {},
   "source": [
    "Nuestra expectativa es que el conjunto de apilamiento funcione mejor que cualquier modelo de base única.\n",
    "Este no es siempre el caso y si no es el caso, entonces el modelo base debe usarse a favor del modelo de conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f167aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    #plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428384a2",
   "metadata": {},
   "source": [
    "En este caso, podemos ver que el conjunto de stacking parece funcionar mejor que cualquier modelo individual en promedio, logrando una precisión de aproximadamente el **96,4** por ciento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6704bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9e2fa9b",
   "metadata": {},
   "source": [
    "### Stacking para Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b575ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare machine learning models for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6a730",
   "metadata": {},
   "source": [
    "Cada algoritmo se evaluará utilizando los hiperparámetros del modelo predeterminados. La función get_models() a continuación crea los modelos que deseamos evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['knn'] = KNeighborsRegressor()\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['svm'] = SVR()\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e6e6b",
   "metadata": {},
   "source": [
    "Cada modelo se evaluará mediante la validación cruzada repetida de k veces. La función evaluate_model() a continuación toma una instancia de modelo y devuelve una lista de puntuaciones de tres repeticiones de validación cruzada de 10 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d09458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5fbc7",
   "metadata": {},
   "source": [
    "En este caso, el rendimiento del modelo se informará utilizando el error absoluto medio (MAE). La biblioteca scikit-learn invierte el signo de este error para maximizarlo, de -infinito a 0 para obtener la mejor puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4957f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f96e695",
   "metadata": {},
   "source": [
    "Ejecutar el ejemplo primero informa la media y la desviación estándar MAE (mean absolute error) para cada modelo. Podemos ver que en este caso, KNN se desempeña mejor con un MAE negativo medio de alrededor de ***-100.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecd78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
